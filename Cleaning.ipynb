{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\clean_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, title, company, location, link, source, date_posted, work_type, employment_type, description]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['title']=='data associate - gurgaon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Pinterest\\n\\nMillions of people around t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            title    company           location  \\\n",
       "0   1     Data Analyst       Meta       New York, NY   \n",
       "1   2     Data Analyst       Meta  San Francisco, CA   \n",
       "2   3     Data Analyst       Meta    Los Angeles, CA   \n",
       "3   4     Data Analyst       Meta     Washington, DC   \n",
       "4   5  Data Analyst II  Pinterest        Chicago, IL   \n",
       "\n",
       "                                                link    source date_posted  \\\n",
       "0  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "1  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "3  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-16   \n",
       "\n",
       "   work_type  employment_type  \\\n",
       "0        NaN              NaN   \n",
       "1        NaN              NaN   \n",
       "2        NaN              NaN   \n",
       "3        NaN              NaN   \n",
       "4        NaN              NaN   \n",
       "\n",
       "                                         description  \n",
       "0  The Social Measurement team is a growing team ...  \n",
       "1  The Social Measurement team is a growing team ...  \n",
       "2  The Social Measurement team is a growing team ...  \n",
       "3  The Social Measurement team is a growing team ...  \n",
       "4  About Pinterest\\n\\nMillions of people around t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first 5 rows \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>691</td>\n",
       "      <td>Data Engineer- Python Pyspark</td>\n",
       "      <td>Virtusa</td>\n",
       "      <td>Chennai, Tamil Nadu, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Data Engineer\\n\\nPosition Summary\\n\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>692</td>\n",
       "      <td>Data Engineer with Pyspark</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job Title:- Data Engineer with Pyspark\\n\\nLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>693</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mercedes-Benz Malaysia</td>\n",
       "      <td>Puchong, Selangor, Malaysia</td>\n",
       "      <td>https://my.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Us\\n\\n\\n\\n\\nAt Mercedes-Benz, we don’t j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>740</td>\n",
       "      <td>Data Engineer I</td>\n",
       "      <td>IntePros</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Engineer I – Infrastructure &amp; Automation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>741</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snap Inc is a technology company. We believe t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                          title                 company  \\\n",
       "322  691  Data Engineer- Python Pyspark                 Virtusa   \n",
       "323  692     Data Engineer with Pyspark               Cognizant   \n",
       "324  693                  Data Engineer  Mercedes-Benz Malaysia   \n",
       "325  740                Data Engineer I                IntePros   \n",
       "326  741                  Data Engineer               Snap Inc.   \n",
       "\n",
       "                              location  \\\n",
       "322         Chennai, Tamil Nadu, India   \n",
       "323  Bangalore Urban, Karnataka, India   \n",
       "324        Puchong, Selangor, Malaysia   \n",
       "325                        Seattle, WA   \n",
       "326                       Bellevue, WA   \n",
       "\n",
       "                                                  link    source date_posted  \\\n",
       "322  https://in.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-10   \n",
       "323  https://in.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-13   \n",
       "324  https://my.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-16   \n",
       "325  https://www.linkedin.com/jobs/view/data-engine...  LinkedIn  2025-04-15   \n",
       "326  https://www.linkedin.com/jobs/view/data-engine...  LinkedIn  2025-04-16   \n",
       "\n",
       "     work_type  employment_type  \\\n",
       "322        NaN              NaN   \n",
       "323        NaN              NaN   \n",
       "324        NaN              NaN   \n",
       "325        NaN              NaN   \n",
       "326        NaN              NaN   \n",
       "\n",
       "                                           description  \n",
       "322  Senior Data Engineer\\n\\nPosition Summary\\n\\nTh...  \n",
       "323  Job Title:- Data Engineer with Pyspark\\n\\nLoca...  \n",
       "324  About Us\\n\\n\\n\\n\\nAt Mercedes-Benz, we don’t j...  \n",
       "325  Data Engineer I – Infrastructure & Automation ...  \n",
       "326  Snap Inc is a technology company. We believe t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get last 5 rows \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               327 non-null    int64  \n",
      " 1   title            327 non-null    object \n",
      " 2   company          327 non-null    object \n",
      " 3   location         327 non-null    object \n",
      " 4   link             327 non-null    object \n",
      " 5   source           327 non-null    object \n",
      " 6   date_posted      327 non-null    object \n",
      " 7   work_type        0 non-null      float64\n",
      " 8   employment_type  0 non-null      float64\n",
      " 9   description      327 non-null    object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 25.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# get some information about our dataset like number of rows in each columns, null and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get num of columns , num of Rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'company', 'location', 'link', 'source', 'date_posted',\n",
       "       'work_type', 'employment_type', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get columns \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "title                0\n",
       "company              0\n",
       "location             0\n",
       "link                 0\n",
       "source               0\n",
       "date_posted          0\n",
       "work_type          327\n",
       "employment_type    327\n",
       "description          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is null value\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the data in a lowercase form\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>data analyst ii</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>about pinterest\\n\\nmillions of people around t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            title    company           location  \\\n",
       "0   1     data analyst       meta       new york, ny   \n",
       "1   2     data analyst       meta  san francisco, ca   \n",
       "2   3     data analyst       meta    los angeles, ca   \n",
       "3   4     data analyst       meta     washington, dc   \n",
       "4   5  data analyst ii  pinterest        chicago, il   \n",
       "\n",
       "                                                link    source date_posted  \\\n",
       "0  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "1  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "3  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-16   \n",
       "\n",
       "   work_type  employment_type  \\\n",
       "0        NaN              NaN   \n",
       "1        NaN              NaN   \n",
       "2        NaN              NaN   \n",
       "3        NaN              NaN   \n",
       "4        NaN              NaN   \n",
       "\n",
       "                                         description  \n",
       "0  the social measurement team is a growing team ...  \n",
       "1  the social measurement team is a growing team ...  \n",
       "2  the social measurement team is a growing team ...  \n",
       "3  the social measurement team is a growing team ...  \n",
       "4  about pinterest\\n\\nmillions of people around t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the changes \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills for data related jobs \n",
    "data_skills = [\n",
    "    'python', 'sql', 'excel', 'power bi', 'tableau', 'r', 'numpy', 'pandas',\n",
    "    'matplotlib', 'seaborn', 'machine learning', 'deep learning', 'tensorflow',\n",
    "    'keras', 'scikit-learn', 'statistics', 'data analysis', 'data visualization',\n",
    "    'etl', 'hadoop', 'spark', 'big data', 'data wrangling', 'dash', 'plotly','dash'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the skills from the description \n",
    "def extract_skills(description):\n",
    "    found_skills = [skill for skill in data_skills if re.search(r'\\b' + re.escape(skill) + r'\\b', description)]\n",
    "    return ', '.join(found_skills) if found_skills else 'None'\n",
    "# adding new column called skills \n",
    "df['skills'] = df['description'].apply(extract_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the work type from the description \n",
    "def extract_work_type(text):\n",
    "    if pd.isna(text):\n",
    "        return 'unknown'\n",
    "    elif any(kw in text for kw in ['remote', 'work from home', 'fully remote']):\n",
    "        return 'remote'\n",
    "    elif any(kw in text for kw in ['onsite', 'on-site', 'office-based']):\n",
    "        return 'onsite'\n",
    "    elif any(kw in text for kw in ['hybrid', 'partially remote', '2 days in office']):\n",
    "        return 'hybrid'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the work type to column work_type \n",
    "df['work_type'] = df['description'].apply(extract_work_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the Minmum skills from the description \n",
    "def extract_min_experience(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "\n",
    "    # Regex pattern to find experience-related phrases\n",
    "    pattern = r'(\\d+)(?:\\+|\\-)?\\s*(\\d+)?\\s*years?'\n",
    "\n",
    "    matches = re.findall(pattern, text.lower())\n",
    "\n",
    "    if matches:\n",
    "        # Convert the first number in the match to integer (minimum years)\n",
    "        min_years = [int(match[0]) for match in matches]\n",
    "        return min(min_years)  # Use min in case there are multiple numbers\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding columns for experience required \n",
    "df['experience'] = df['description'].apply(extract_min_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric \n",
    "df['experience'] = pd.to_numeric(df['experience'], errors='coerce')\n",
    "# Make a threshold of 15 year of experience \n",
    "df = df[df['experience'] <= 15]\n",
    "# fill null values with the min experience of 0 \n",
    "df['experience'] = df['experience'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns the irrelavent and doesn't add somthing new and doesn't contain any thing \n",
    "df.drop(['id','link','source', 'employment_type','description'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 228 entries, 0 to 326\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        228 non-null    object \n",
      " 1   company      228 non-null    object \n",
      " 2   location     228 non-null    object \n",
      " 3   date_posted  228 non-null    object \n",
      " 4   work_type    228 non-null    object \n",
      " 5   skills       228 non-null    object \n",
      " 6   experience   228 non-null    float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# get some information about our dataset like number of rows in each columns, null and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the duplicates \n",
    "df[['title','company','location']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>fremont, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>data engineer i, scot - aim</td>\n",
       "      <td>amazon</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, etl, hadoop, spark, big data</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>infrastructure partner data engineer, youtube</td>\n",
       "      <td>google</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, power bi, tableau, machine learning, e...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>data engineer i, scot - aim</td>\n",
       "      <td>amazon</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, etl, hadoop, spark, big data</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>data engineer i, scot - aim</td>\n",
       "      <td>amazon</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, etl, hadoop, spark, big data</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title company  \\\n",
       "195              data scientist, product analytics    meta   \n",
       "196              data scientist, product analytics    meta   \n",
       "197              data scientist, product analytics    meta   \n",
       "198              data scientist, product analytics    meta   \n",
       "215              data scientist, product analytics    meta   \n",
       "252               data engineer, product analytics    meta   \n",
       "255               data engineer, product analytics    meta   \n",
       "263               data engineer, product analytics    meta   \n",
       "265               data engineer, product analytics    meta   \n",
       "269               data engineer, product analytics    meta   \n",
       "298                    data engineer i, scot - aim  amazon   \n",
       "301  infrastructure partner data engineer, youtube  google   \n",
       "303                    data engineer i, scot - aim  amazon   \n",
       "305                    data engineer i, scot - aim  amazon   \n",
       "\n",
       "                        location date_posted work_type  \\\n",
       "195                 new york, ny  2025-04-14   unknown   \n",
       "196                 new york, ny  2025-04-14   unknown   \n",
       "197            san francisco, ca  2025-04-14   unknown   \n",
       "198            san francisco, ca  2025-04-14   unknown   \n",
       "215               washington, dc  2025-04-14   unknown   \n",
       "252            san francisco, ca  2025-04-14   unknown   \n",
       "255                 new york, ny  2025-04-14   unknown   \n",
       "263                  fremont, ca  2025-04-14   unknown   \n",
       "265                 new york, ny  2025-04-14   unknown   \n",
       "269            san francisco, ca  2025-04-14   unknown   \n",
       "298  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "301  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "303  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "305  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "\n",
       "                                                skills  experience  \n",
       "195       python, sql, r, machine learning, statistics         4.0  \n",
       "196       python, sql, r, machine learning, statistics         2.0  \n",
       "197       python, sql, r, machine learning, statistics         4.0  \n",
       "198       python, sql, r, machine learning, statistics         2.0  \n",
       "215       python, sql, r, machine learning, statistics         2.0  \n",
       "252                 python, sql, machine learning, etl         2.0  \n",
       "255                 python, sql, machine learning, etl         4.0  \n",
       "263                 python, sql, machine learning, etl         2.0  \n",
       "265                 python, sql, machine learning, etl         7.0  \n",
       "269                 python, sql, machine learning, etl         4.0  \n",
       "298          python, sql, etl, hadoop, spark, big data         1.0  \n",
       "301  python, power bi, tableau, machine learning, e...         3.0  \n",
       "303          python, sql, etl, hadoop, spark, big data         1.0  \n",
       "305          python, sql, etl, hadoop, spark, big data         1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get them \n",
    "df[df[['title','company','location']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping the duplicatees \n",
    "df = df.drop_duplicates(subset=['title', 'company', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the duplicates \n",
    "df[['title','company','location']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the datatype of the column date_post to datetime\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "company        0\n",
       "location       0\n",
       "date_posted    0\n",
       "work_type      0\n",
       "skills         0\n",
       "experience     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the nulls \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data analyst', 'data analyst ii', 'data analyst - marketing',\n",
       "       'data analyst, global partnerships & content',\n",
       "       'senior data analyst', 'data products analyst, youtube',\n",
       "       'customer relationship management analyst', 'analytics associate',\n",
       "       'data analyst i', 'data & analytics, analyst',\n",
       "       'people data analyst', 'customer insights analyst',\n",
       "       'analyst, data science, rmbs', 'analyst', 'business data analyst',\n",
       "       'junior data analyst', 'healthcare data analyst i - remote',\n",
       "       'data analyst - 100% remote', 'sr. data analyst',\n",
       "       'data analyst contractor', 'data platform analyst, subscriptions',\n",
       "       'lead data analyst (power bi,sql)', 'data analytics',\n",
       "       'analyst-data science', 'analyst, data science', 'sr data analyst',\n",
       "       'data analyst (data visualization)', 'data associate - gurgaon',\n",
       "       'data analyst - local to pittsburgh or cleveland',\n",
       "       'jr. data & bi analyst', 'data scientist, product, sustainability',\n",
       "       'data scientist, product analytics', 'fraud data scientist',\n",
       "       'senior data scientist', 'data scientist',\n",
       "       'machine learning engineer (l5) - content & media ml foundations',\n",
       "       'data scientist - last mile', 'jr. data scientist',\n",
       "       'data scientist, marketing science', 'ai/ml engineer',\n",
       "       'staff data scientist, strategy & insights', 'data scientist i',\n",
       "       'data scientist/analyst', 'gen ai/ml',\n",
       "       'data scientist, fundamental sector data',\n",
       "       'data scientist (business operations)',\n",
       "       'junior artificial intelligence (ai) / machine learning (ml) engineer',\n",
       "       'junior frontend developer', 'machine learning engineer',\n",
       "       'product data scientist', 'research and development scientist',\n",
       "       'data scientist (ai/ml)', 'machine learning engineer (junior)',\n",
       "       'ai/ml developer', 'data scientist, consumer research & marketing',\n",
       "       'data scientist, marketing', 'ai engineer',\n",
       "       'data scientist iii, product, operations data science',\n",
       "       'data scientist iii (commercial analytics)',\n",
       "       'data engineer (l5) - conversation',\n",
       "       'data engineer (l4) - security', 'data engineer',\n",
       "       'data engineer, play data science and analytics',\n",
       "       'data engineer, infrastructure',\n",
       "       'analytics engineer (l4) - acquisition',\n",
       "       'data engineer, product analytics',\n",
       "       'data engineer i (full time) united states',\n",
       "       'software engineer l4, machine learning platform (metaflow)',\n",
       "       'senior data engineer', 'senior, data engineer',\n",
       "       'data engineer - people analytics', 'data engineer, vx analytics',\n",
       "       'sr. data engineer', 'data engineer iii',\n",
       "       'data engineer, analytics (technical leadership)',\n",
       "       'remote engineer, data, i', 'data engineer jr.',\n",
       "       'data engineer, digital acceleration', '(usa) data engineer iii',\n",
       "       'data engineer i, in-ads', 'data engineer - python',\n",
       "       'data engineer with python + sql', 'data engineer, marketplace',\n",
       "       'infrastructure partner data engineer',\n",
       "       'data engineer i, scot - aim',\n",
       "       'infrastructure partner data engineer, youtube',\n",
       "       'data operation engineer i', 'data engineer(aws)',\n",
       "       'associate data engineer', 'data engineer - c10',\n",
       "       'data engineer - enterprise data operations analyst',\n",
       "       'data engineer - c11',\n",
       "       'python & sql data engineer_director_software engineering',\n",
       "       'senior software engineer, systems infrastructure',\n",
       "       'data engineer (platform)', 'data engineer- python pyspark',\n",
       "       'data engineer with pyspark', 'data engineer i'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knowing the unique values to replace them to the same job title \n",
    "df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace full cell if it contains analysis-related words\n",
    "df.loc[df['title'].str.contains(r'\\b(analyst|analysis|analista|analytics|associate - gurgaon|intern)\\b', regex=True), 'title'] = 'data analysis'\n",
    "\n",
    "# Replace full cell if it contains (scientist or cientista)\n",
    "df.loc[df['title'].str.contains(r'\\b.*\\b(scientist|cientista)\\b', regex=True), 'title'] = 'data science'\n",
    "\n",
    "# Replace full cell if it contains engineer or engineering\n",
    "df.loc[df['title'].str.contains(r'\\b.*\\b(engineer|engineering)\\b', regex=True), 'title'] = 'data engineering'\n",
    "\n",
    "# Replace full cell if it contains machine + learning or ai/ml\n",
    "df.loc[df['title'].str.contains(r'\\bmachine\\b.*\\blearning\\b|\\b(ai|ml)\\b', regex=True), 'title'] = 'machine learning & AI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>fanduel</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>python, sql, excel, tableau, data visualization</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>fanduel</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, excel, tableau, r, data visualiza...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>sbh fashion</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>remote</td>\n",
       "      <td>python, sql, excel, tableau, data analysis, da...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sql, machine learning, data analysis</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>fanduel</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>python, sql, excel, tableau, data visualization</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>finthrive</td>\n",
       "      <td>united states</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sql, excel, power bi, tableau, data analysis, etl</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>alice + olivia</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sql, excel, statistics, data analysis</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>google</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, statistics, etl...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>bvlgari</td>\n",
       "      <td>new york city metropolitan area</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>unknown</td>\n",
       "      <td>excel, statistics, data analysis</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>hamilton porter</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>onsite</td>\n",
       "      <td>python, tableau</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>brooklinen</td>\n",
       "      <td>brooklyn, ny</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>remote</td>\n",
       "      <td>python, sql, power bi, tableau, r, statistics,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>equip</td>\n",
       "      <td>united states</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>remote</td>\n",
       "      <td>sql, tableau</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>toyota north america</td>\n",
       "      <td>plano, tx</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>python, sql, excel, tableau, r, statistics</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title               company                         location  \\\n",
       "0   data analysis                  meta                     new york, ny   \n",
       "1   data analysis                  meta                san francisco, ca   \n",
       "2   data analysis                  meta                  los angeles, ca   \n",
       "3   data analysis                  meta                   washington, dc   \n",
       "4   data analysis             pinterest                      chicago, il   \n",
       "5   data analysis               fanduel                     new york, ny   \n",
       "7   data analysis               fanduel                     new york, ny   \n",
       "8   data analysis           sbh fashion                     new york, ny   \n",
       "9   data analysis             pinterest                     new york, ny   \n",
       "10  data analysis             pinterest                san francisco, ca   \n",
       "11  data analysis                  meta                     new york, ny   \n",
       "12  data analysis               fanduel                      atlanta, ga   \n",
       "13  data analysis             finthrive                    united states   \n",
       "14  data analysis        alice + olivia                     new york, ny   \n",
       "15  data analysis                google                     new york, ny   \n",
       "16  data analysis               bvlgari  new york city metropolitan area   \n",
       "19  data analysis       hamilton porter                     new york, ny   \n",
       "20  data analysis            brooklinen                     brooklyn, ny   \n",
       "21  data analysis                 equip                    united states   \n",
       "22  data analysis  toyota north america                        plano, tx   \n",
       "\n",
       "   date_posted work_type                                             skills  \\\n",
       "0   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "1   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "2   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "3   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "4   2025-04-16   unknown                            python, sql, statistics   \n",
       "5   2025-04-11    hybrid    python, sql, excel, tableau, data visualization   \n",
       "7   2025-04-13   unknown  python, sql, excel, tableau, r, data visualiza...   \n",
       "8   2025-04-12    remote  python, sql, excel, tableau, data analysis, da...   \n",
       "9   2025-04-16   unknown                            python, sql, statistics   \n",
       "10  2025-04-16   unknown                            python, sql, statistics   \n",
       "11  2025-04-14   unknown               sql, machine learning, data analysis   \n",
       "12  2025-04-11    hybrid    python, sql, excel, tableau, data visualization   \n",
       "13  2025-04-15   unknown  sql, excel, power bi, tableau, data analysis, etl   \n",
       "14  2025-04-15   unknown              sql, excel, statistics, data analysis   \n",
       "15  2025-04-14   unknown  python, sql, machine learning, statistics, etl...   \n",
       "16  2025-04-11   unknown                   excel, statistics, data analysis   \n",
       "19  2025-04-16    onsite                                    python, tableau   \n",
       "20  2025-04-10    remote  python, sql, power bi, tableau, r, statistics,...   \n",
       "21  2025-04-16    remote                                       sql, tableau   \n",
       "22  2025-04-15    hybrid         python, sql, excel, tableau, r, statistics   \n",
       "\n",
       "    experience  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          4.0  \n",
       "5          3.0  \n",
       "7          2.0  \n",
       "8          3.0  \n",
       "9          4.0  \n",
       "10         4.0  \n",
       "11         5.0  \n",
       "12         3.0  \n",
       "13         1.0  \n",
       "14         5.0  \n",
       "15         3.0  \n",
       "16         3.0  \n",
       "19         5.0  \n",
       "20         1.0  \n",
       "21         2.0  \n",
       "22         3.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data analysis', 'data science', 'data engineering',\n",
       "       'machine learning & AI', 'junior frontend developer'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check after replacement \n",
    "df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this unique row that doesn't related wiht the data jobs \n",
    "df = df[df['title']!='junior frontend developer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Drop rows where skills is None or empty\n",
    "skills_series = df['skills'].dropna()\n",
    "skills_list = []\n",
    "\n",
    "for skills in skills_series:\n",
    "    skills_split = [skill.strip() for skill in skills.split(',') if skill.strip().lower() != 'none']\n",
    "    skills_list.extend(skills_split)\n",
    "\n",
    "# Count the frequency of each skill\n",
    "skill_counts = Counter(skills_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'python': 174,\n",
       "         'sql': 173,\n",
       "         'machine learning': 93,\n",
       "         'statistics': 82,\n",
       "         'etl': 75,\n",
       "         'tableau': 62,\n",
       "         'r': 59,\n",
       "         'spark': 57,\n",
       "         'data analysis': 53,\n",
       "         'big data': 44,\n",
       "         'data visualization': 40,\n",
       "         'power bi': 33,\n",
       "         'excel': 29,\n",
       "         'hadoop': 22,\n",
       "         'deep learning': 19,\n",
       "         'tensorflow': 18,\n",
       "         'scikit-learn': 13,\n",
       "         'pandas': 11,\n",
       "         'numpy': 9,\n",
       "         'keras': 8,\n",
       "         'data wrangling': 5,\n",
       "         'matplotlib': 3,\n",
       "         'plotly': 1,\n",
       "         'seaborn': 1})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_job.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
