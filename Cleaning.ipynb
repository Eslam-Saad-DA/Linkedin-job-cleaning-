{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linkedin Data-Related Jobs Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\DELL\\Desktop\\clean_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Pinterest\\n\\nMillions of people around t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            title    company           location  \\\n",
       "0   1     Data Analyst       Meta       New York, NY   \n",
       "1   2     Data Analyst       Meta  San Francisco, CA   \n",
       "2   3     Data Analyst       Meta    Los Angeles, CA   \n",
       "3   4     Data Analyst       Meta     Washington, DC   \n",
       "4   5  Data Analyst II  Pinterest        Chicago, IL   \n",
       "\n",
       "                                                link    source date_posted  \\\n",
       "0  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "1  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "3  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-16   \n",
       "\n",
       "   work_type  employment_type  \\\n",
       "0        NaN              NaN   \n",
       "1        NaN              NaN   \n",
       "2        NaN              NaN   \n",
       "3        NaN              NaN   \n",
       "4        NaN              NaN   \n",
       "\n",
       "                                         description  \n",
       "0  The Social Measurement team is a growing team ...  \n",
       "1  The Social Measurement team is a growing team ...  \n",
       "2  The Social Measurement team is a growing team ...  \n",
       "3  The Social Measurement team is a growing team ...  \n",
       "4  About Pinterest\\n\\nMillions of people around t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get first 5 rows \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>691</td>\n",
       "      <td>Data Engineer- Python Pyspark</td>\n",
       "      <td>Virtusa</td>\n",
       "      <td>Chennai, Tamil Nadu, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Data Engineer\\n\\nPosition Summary\\n\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>692</td>\n",
       "      <td>Data Engineer with Pyspark</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Bangalore Urban, Karnataka, India</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job Title:- Data Engineer with Pyspark\\n\\nLoca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>693</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mercedes-Benz Malaysia</td>\n",
       "      <td>Puchong, Selangor, Malaysia</td>\n",
       "      <td>https://my.linkedin.com/jobs/view/data-enginee...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Us\\n\\n\\n\\n\\nAt Mercedes-Benz, we don’t j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>740</td>\n",
       "      <td>Data Engineer I</td>\n",
       "      <td>IntePros</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Engineer I – Infrastructure &amp; Automation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>741</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Snap Inc is a technology company. We believe t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                          title                 company  \\\n",
       "322  691  Data Engineer- Python Pyspark                 Virtusa   \n",
       "323  692     Data Engineer with Pyspark               Cognizant   \n",
       "324  693                  Data Engineer  Mercedes-Benz Malaysia   \n",
       "325  740                Data Engineer I                IntePros   \n",
       "326  741                  Data Engineer               Snap Inc.   \n",
       "\n",
       "                              location  \\\n",
       "322         Chennai, Tamil Nadu, India   \n",
       "323  Bangalore Urban, Karnataka, India   \n",
       "324        Puchong, Selangor, Malaysia   \n",
       "325                        Seattle, WA   \n",
       "326                       Bellevue, WA   \n",
       "\n",
       "                                                  link    source date_posted  \\\n",
       "322  https://in.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-10   \n",
       "323  https://in.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-13   \n",
       "324  https://my.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-16   \n",
       "325  https://www.linkedin.com/jobs/view/data-engine...  LinkedIn  2025-04-15   \n",
       "326  https://www.linkedin.com/jobs/view/data-engine...  LinkedIn  2025-04-16   \n",
       "\n",
       "     work_type  employment_type  \\\n",
       "322        NaN              NaN   \n",
       "323        NaN              NaN   \n",
       "324        NaN              NaN   \n",
       "325        NaN              NaN   \n",
       "326        NaN              NaN   \n",
       "\n",
       "                                           description  \n",
       "322  Senior Data Engineer\\n\\nPosition Summary\\n\\nTh...  \n",
       "323  Job Title:- Data Engineer with Pyspark\\n\\nLoca...  \n",
       "324  About Us\\n\\n\\n\\n\\nAt Mercedes-Benz, we don’t j...  \n",
       "325  Data Engineer I – Infrastructure & Automation ...  \n",
       "326  Snap Inc is a technology company. We believe t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get last 5 rows \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               327 non-null    int64  \n",
      " 1   title            327 non-null    object \n",
      " 2   company          327 non-null    object \n",
      " 3   location         327 non-null    object \n",
      " 4   link             327 non-null    object \n",
      " 5   source           327 non-null    object \n",
      " 6   date_posted      327 non-null    object \n",
      " 7   work_type        0 non-null      float64\n",
      " 8   employment_type  0 non-null      float64\n",
      " 9   description      327 non-null    object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 25.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# get some information about our dataset like number of rows in each columns, null and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get num of columns , num of Rows\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'company', 'location', 'link', 'source', 'date_posted',\n",
       "       'work_type', 'employment_type', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get columns \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "title                0\n",
       "company              0\n",
       "location             0\n",
       "link                 0\n",
       "source               0\n",
       "date_posted          0\n",
       "work_type          327\n",
       "employment_type    327\n",
       "description          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is null value\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the data in a lowercase form\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>meta</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the social measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>data analyst ii</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>linkedin</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>about pinterest\\n\\nmillions of people around t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            title    company           location  \\\n",
       "0   1     data analyst       meta       new york, ny   \n",
       "1   2     data analyst       meta  san francisco, ca   \n",
       "2   3     data analyst       meta    los angeles, ca   \n",
       "3   4     data analyst       meta     washington, dc   \n",
       "4   5  data analyst ii  pinterest        chicago, il   \n",
       "\n",
       "                                                link    source date_posted  \\\n",
       "0  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "1  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "3  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-14   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  linkedin  2025-04-16   \n",
       "\n",
       "   work_type  employment_type  \\\n",
       "0        NaN              NaN   \n",
       "1        NaN              NaN   \n",
       "2        NaN              NaN   \n",
       "3        NaN              NaN   \n",
       "4        NaN              NaN   \n",
       "\n",
       "                                         description  \n",
       "0  the social measurement team is a growing team ...  \n",
       "1  the social measurement team is a growing team ...  \n",
       "2  the social measurement team is a growing team ...  \n",
       "3  the social measurement team is a growing team ...  \n",
       "4  about pinterest\\n\\nmillions of people around t...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the changes \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills for data related jobs \n",
    "data_skills = [\n",
    "    'python', 'sql', 'excel', 'power bi', 'tableau', 'r', 'numpy', 'pandas',\n",
    "    'matplotlib', 'seaborn', 'machine learning', 'deep learning', 'tensorflow',\n",
    "    'keras', 'scikit-learn', 'statistics', 'data analysis', 'data visualization',\n",
    "    'etl', 'hadoop', 'spark', 'big data', 'data wrangling', 'dash', 'plotly','dash'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the skills from the description \n",
    "def extract_skills(description):\n",
    "    found_skills = [skill for skill in data_skills if re.search(r'\\b' + re.escape(skill) + r'\\b', description)]\n",
    "    return ', '.join(found_skills) if found_skills else 'None'\n",
    "# adding new column called skills \n",
    "df['skills'] = df['description'].apply(extract_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the work type from the description \n",
    "def extract_work_type(text):\n",
    "    if pd.isna(text):\n",
    "        return 'unknown'\n",
    "    elif any(kw in text for kw in ['remote', 'work from home', 'fully remote']):\n",
    "        return 'remote'\n",
    "    elif any(kw in text for kw in ['onsite', 'on-site', 'office-based']):\n",
    "        return 'onsite'\n",
    "    elif any(kw in text for kw in ['hybrid', 'partially remote', '2 days in office']):\n",
    "        return 'hybrid'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the work type to column work_type \n",
    "df['work_type'] = df['description'].apply(extract_work_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the Minmum skills from the description \n",
    "def extract_min_experience(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "\n",
    "    # Regex pattern to find experience-related phrases\n",
    "    pattern = r'(\\d+)(?:\\+|\\-)?\\s*(\\d+)?\\s*years?'\n",
    "\n",
    "    matches = re.findall(pattern, text.lower())\n",
    "\n",
    "    if matches:\n",
    "        # Convert the first number in the match to integer (minimum years)\n",
    "        min_years = [int(match[0]) for match in matches]\n",
    "        return min(min_years)  # Use min in case there are multiple numbers\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding columns for experience required \n",
    "df['experience'] = df['description'].apply(extract_min_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric \n",
    "df['experience'] = pd.to_numeric(df['experience'], errors='coerce')\n",
    "\n",
    "# fill null values with the min experience of 0 \n",
    "df['experience'] = df['experience'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns the irrelavent and doesn't add somthing new and doesn't contain any thing \n",
    "df.drop(['id','link','source', 'employment_type','description'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        327 non-null    object \n",
      " 1   company      327 non-null    object \n",
      " 2   location     327 non-null    object \n",
      " 3   date_posted  327 non-null    object \n",
      " 4   work_type    327 non-null    object \n",
      " 5   skills       327 non-null    object \n",
      " 6   experience   327 non-null    float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 18.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# get some information about our dataset like number of rows in each columns, null and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the duplicates \n",
    "df[['title','company','location']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>pt indofood cbp sukses makmur tbk - noodle div...</td>\n",
       "      <td>jakarta, jakarta, indonesia</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sql, excel</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>explore group</td>\n",
       "      <td>london area, united kingdom</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>remote</td>\n",
       "      <td>sql, power bi, tableau, data visualization</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>seattle, wa</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>burlingame, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>bellevue, wa</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>menlo park, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>sunnyvale, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>data scientist, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>austin, tx</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, r, machine learning, statistics</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>fremont, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>data engineer, product analytics</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, etl</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>data engineer</td>\n",
       "      <td>thomson reuters</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>onsite</td>\n",
       "      <td>python, sql, power bi, tableau</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>data engineer i, scot - aim</td>\n",
       "      <td>amazon</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, etl, hadoop, spark, big data</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>infrastructure partner data engineer, youtube</td>\n",
       "      <td>google</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, power bi, tableau, machine learning, e...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>data engineer i, scot - aim</td>\n",
       "      <td>amazon</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, etl, hadoop, spark, big data</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>data engineer i, scot - aim</td>\n",
       "      <td>amazon</td>\n",
       "      <td>bengaluru, karnataka, india</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, etl, hadoop, spark, big data</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "68                                    data analyst   \n",
       "79                                    data analyst   \n",
       "118              data scientist, product analytics   \n",
       "195              data scientist, product analytics   \n",
       "196              data scientist, product analytics   \n",
       "197              data scientist, product analytics   \n",
       "198              data scientist, product analytics   \n",
       "200              data scientist, product analytics   \n",
       "206              data scientist, product analytics   \n",
       "207              data scientist, product analytics   \n",
       "208              data scientist, product analytics   \n",
       "215              data scientist, product analytics   \n",
       "218              data scientist, product analytics   \n",
       "220              data scientist, product analytics   \n",
       "252               data engineer, product analytics   \n",
       "255               data engineer, product analytics   \n",
       "263               data engineer, product analytics   \n",
       "265               data engineer, product analytics   \n",
       "269               data engineer, product analytics   \n",
       "291                                  data engineer   \n",
       "298                    data engineer i, scot - aim   \n",
       "301  infrastructure partner data engineer, youtube   \n",
       "303                    data engineer i, scot - aim   \n",
       "305                    data engineer i, scot - aim   \n",
       "\n",
       "                                               company  \\\n",
       "68   pt indofood cbp sukses makmur tbk - noodle div...   \n",
       "79                                       explore group   \n",
       "118                                               meta   \n",
       "195                                               meta   \n",
       "196                                               meta   \n",
       "197                                               meta   \n",
       "198                                               meta   \n",
       "200                                               meta   \n",
       "206                                               meta   \n",
       "207                                               meta   \n",
       "208                                               meta   \n",
       "215                                               meta   \n",
       "218                                               meta   \n",
       "220                                               meta   \n",
       "252                                               meta   \n",
       "255                                               meta   \n",
       "263                                               meta   \n",
       "265                                               meta   \n",
       "269                                               meta   \n",
       "291                                    thomson reuters   \n",
       "298                                             amazon   \n",
       "301                                             google   \n",
       "303                                             amazon   \n",
       "305                                             amazon   \n",
       "\n",
       "                        location date_posted work_type  \\\n",
       "68   jakarta, jakarta, indonesia  2025-04-16   unknown   \n",
       "79   london area, united kingdom  2025-04-16    remote   \n",
       "118                  seattle, wa  2025-04-14   unknown   \n",
       "195                 new york, ny  2025-04-14   unknown   \n",
       "196                 new york, ny  2025-04-14   unknown   \n",
       "197            san francisco, ca  2025-04-14   unknown   \n",
       "198            san francisco, ca  2025-04-14   unknown   \n",
       "200            san francisco, ca  2025-04-14   unknown   \n",
       "206               burlingame, ca  2025-04-14   unknown   \n",
       "207                 bellevue, wa  2025-04-14   unknown   \n",
       "208               menlo park, ca  2025-04-14   unknown   \n",
       "215               washington, dc  2025-04-14   unknown   \n",
       "218                sunnyvale, ca  2025-04-14   unknown   \n",
       "220                   austin, tx  2025-04-14   unknown   \n",
       "252            san francisco, ca  2025-04-14   unknown   \n",
       "255                 new york, ny  2025-04-14   unknown   \n",
       "263                  fremont, ca  2025-04-14   unknown   \n",
       "265                 new york, ny  2025-04-14   unknown   \n",
       "269            san francisco, ca  2025-04-14   unknown   \n",
       "291  bengaluru, karnataka, india  2025-04-11    onsite   \n",
       "298  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "301  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "303  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "305  bengaluru, karnataka, india  2025-04-12   unknown   \n",
       "\n",
       "                                                skills  experience  \n",
       "68                                          sql, excel         0.0  \n",
       "79          sql, power bi, tableau, data visualization         0.0  \n",
       "118       python, sql, r, machine learning, statistics         2.0  \n",
       "195       python, sql, r, machine learning, statistics         4.0  \n",
       "196       python, sql, r, machine learning, statistics         2.0  \n",
       "197       python, sql, r, machine learning, statistics         4.0  \n",
       "198       python, sql, r, machine learning, statistics         2.0  \n",
       "200       python, sql, r, machine learning, statistics         0.0  \n",
       "206       python, sql, r, machine learning, statistics         0.0  \n",
       "207       python, sql, r, machine learning, statistics         0.0  \n",
       "208       python, sql, r, machine learning, statistics         2.0  \n",
       "215       python, sql, r, machine learning, statistics         2.0  \n",
       "218                   python, sql, r, machine learning         2.0  \n",
       "220       python, sql, r, machine learning, statistics         2.0  \n",
       "252                 python, sql, machine learning, etl         2.0  \n",
       "255                 python, sql, machine learning, etl         4.0  \n",
       "263                 python, sql, machine learning, etl         2.0  \n",
       "265                 python, sql, machine learning, etl         7.0  \n",
       "269                 python, sql, machine learning, etl         4.0  \n",
       "291                     python, sql, power bi, tableau       160.0  \n",
       "298          python, sql, etl, hadoop, spark, big data         1.0  \n",
       "301  python, power bi, tableau, machine learning, e...         3.0  \n",
       "303          python, sql, etl, hadoop, spark, big data         1.0  \n",
       "305          python, sql, etl, hadoop, spark, big data         1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get them \n",
    "df[df[['title','company','location']].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping the duplicatees \n",
    "df = df.drop_duplicates(subset=['title', 'company', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the duplicates \n",
    "df[['title','company','location']].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the datatype of the column date_post to datetime\n",
    "df['date_posted'] = pd.to_datetime(df['date_posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "company        0\n",
       "location       0\n",
       "date_posted    0\n",
       "work_type      0\n",
       "skills         0\n",
       "experience     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the nulls \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data analyst', 'data analyst ii',\n",
       "       'data analyst, production finance operations & innovation',\n",
       "       'data analyst - marketing',\n",
       "       'data analyst, global partnerships & content',\n",
       "       'senior data analyst', 'data products analyst, youtube',\n",
       "       'customer relationship management analyst',\n",
       "       'data analyst - sql, erp', 'marketing data analyst',\n",
       "       'analytics associate', 'data analyst i',\n",
       "       'data & analytics, analyst', 'junior data analyst - remote',\n",
       "       'people data analyst', 'customer insights analyst',\n",
       "       'data analyst intern (fall start)', 'analyst, data science, rmbs',\n",
       "       'analyst', 'business data analyst', 'junior data analyst',\n",
       "       'healthcare data analyst i - remote', 'data analyst - 100% remote',\n",
       "       'insights analyst', 'sr. data analyst', 'data analyst contractor',\n",
       "       'analyst, data analytics & intelligence',\n",
       "       'analista de dados junior - são paulo/sp',\n",
       "       'data platform analyst, subscriptions', 'healthcare data analyst',\n",
       "       'junior data analyst uk&i', 'lead data analyst (power bi,sql)',\n",
       "       'officer - real time analytics',\n",
       "       'analista gestao de indicadores pl', 'data analytics',\n",
       "       'analista de dados júnior | data viz', 'analyst-data science',\n",
       "       'analyst, data science', 'data analyst intern',\n",
       "       'analista de dados júnior', 'sr data analyst',\n",
       "       'data analyst (data visualization)',\n",
       "       'analista de business intelligence júnior',\n",
       "       'data associate - gurgaon',\n",
       "       'data analyst - local to pittsburgh or cleveland',\n",
       "       'analista de análise de dados junior', 'data intern',\n",
       "       'jr. data & bi analyst', 'data scientist, product analytics',\n",
       "       'data scientist, product, sustainability', 'fraud data scientist',\n",
       "       'senior data scientist', 'data scientist',\n",
       "       'machine learning engineer (l5) - content & media ml foundations',\n",
       "       'data scientist - last mile',\n",
       "       'partner data scientist, growth partnerships',\n",
       "       'jr. data scientist', 'data scientist, marketing science',\n",
       "       'ai/ml engineer',\n",
       "       'data scientist- customer lifecycle and engagement',\n",
       "       'cientista de dados ii - área prevenção a fraudes',\n",
       "       'graduate data scientist',\n",
       "       'staff data scientist, strategy & insights', 'data scientist i',\n",
       "       'data scientist/analyst', 'gen ai/ml',\n",
       "       'data scientist, fundamental sector data',\n",
       "       'machine learning engineer (berlin, germany)',\n",
       "       'data scientist (l5) - app qoe',\n",
       "       'data scientist (business operations)',\n",
       "       'junior artificial intelligence (ai) / machine learning (ml) engineer',\n",
       "       'junior frontend developer',\n",
       "       'data scientist (climate & geospatial)', 'data scientist jr.',\n",
       "       'cientista de dados - estágio', 'machine learning engineer',\n",
       "       'data scientist (entry level)', 'product data scientist',\n",
       "       'research and development scientist',\n",
       "       'data scientist senior - mlops & transformation (f/h)',\n",
       "       'junior data scientist', 'data scientist-1',\n",
       "       'data scientist strategy & value creation consulting',\n",
       "       'data scientist (m/f/d)', 'data scientist (ai/ml)',\n",
       "       'data scientist/sr data scientist',\n",
       "       'machine learning engineer (junior)', 'ai/ml developer',\n",
       "       'ai/ml researcher',\n",
       "       'data scientist, consumer research & marketing',\n",
       "       'data scientist, marketing', 'ai engineer',\n",
       "       'data scientist iii, product, operations data science',\n",
       "       'machine learning software engineer (l5) - content and studio',\n",
       "       'data scientist iii (commercial analytics)',\n",
       "       'data engineer (l5) - conversation',\n",
       "       'data engineer (l4) - security', 'data engineer',\n",
       "       'data engineer, play data science and analytics',\n",
       "       'data engineer, infrastructure',\n",
       "       'ml software engineer (l4/l5) - media algorithms',\n",
       "       'analytics engineer (l4) - acquisition',\n",
       "       'data engineer, product analytics',\n",
       "       'data engineer i (full time) united states',\n",
       "       'software engineer l4, machine learning platform (metaflow)',\n",
       "       'software engineer 5, data clean room', 'senior data engineer',\n",
       "       'data engineer graduate (ads data application) - 2025 start (bs/ms)',\n",
       "       'senior, data engineer',\n",
       "       'software engineer, ai platform - new grad',\n",
       "       'data engineer - people analytics', 'data engineer, e-commerce',\n",
       "       'data engineer, vx analytics', 'sr. data engineer',\n",
       "       'data engineer iii',\n",
       "       'data engineer, analytics (technical leadership)',\n",
       "       'remote engineer, data, i', 'sr. data engineer, analytics',\n",
       "       'data engineer jr.', 'data engineer - subscriptions',\n",
       "       'data engineer, digital acceleration', '(usa) data engineer iii',\n",
       "       'data engineer (university grad)', 'data engineer i, in-ads',\n",
       "       'data engineer - python', 'data engineer with python + sql',\n",
       "       'data engineer, marketplace', 'uk 2025 data engineer internship',\n",
       "       'infrastructure partner data engineer',\n",
       "       'data engineer i, scot - aim',\n",
       "       'infrastructure partner data engineer, youtube',\n",
       "       'data operation engineer i', 'data engineer(aws)',\n",
       "       'associate data engineer', 'data engineer - c10',\n",
       "       'data engineer - commerce platform',\n",
       "       'data engineer - enterprise data operations analyst',\n",
       "       'jr. data engineer', 'data engineer - c11',\n",
       "       'python & sql data engineer_director_software engineering',\n",
       "       'senior software engineer, systems infrastructure',\n",
       "       'data analytics engineer', 'data engineer (platform)',\n",
       "       'data engineer- python pyspark', 'data engineer with pyspark',\n",
       "       'data engineer i'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knowing the unique values to replace them to the same job title \n",
    "df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace full cell if it contains analysis-related words\n",
    "df.loc[df['title'].str.contains(r'\\b(analyst|analysis|analista|analytics|associate - gurgaon|intern)\\b', regex=True), 'title'] = 'data analysis'\n",
    "\n",
    "# Replace full cell if it contains (scientist or cientista)\n",
    "df.loc[df['title'].str.contains(r'\\b.*\\b(scientist|cientista)\\b', regex=True), 'title'] = 'data science'\n",
    "\n",
    "# Replace full cell if it contains engineer or engineering\n",
    "df.loc[df['title'].str.contains(r'\\b.*\\b(engineer|engineering)\\b', regex=True), 'title'] = 'data engineering'\n",
    "\n",
    "# Replace full cell if it contains machine + learning or ai/ml\n",
    "df.loc[df['title'].str.contains(r'\\bmachine\\b.*\\blearning\\b|\\b(ai|ml)\\b', regex=True), 'title'] = 'machine learning & AI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, tableau, r, machine learning, sta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>fanduel</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>python, sql, excel, tableau, data visualization</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>netflix</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, data analysis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>fanduel</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-13</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, excel, tableau, r, data visualiza...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>sbh fashion</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-12</td>\n",
       "      <td>remote</td>\n",
       "      <td>python, sql, excel, tableau, data analysis, da...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>pinterest</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, statistics</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>meta</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sql, machine learning, data analysis</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>fanduel</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>python, sql, excel, tableau, data visualization</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>finthrive</td>\n",
       "      <td>united states</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sql, excel, power bi, tableau, data analysis, etl</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>alice + olivia</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>unknown</td>\n",
       "      <td>sql, excel, statistics, data analysis</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>google</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python, sql, machine learning, statistics, etl...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>bvlgari</td>\n",
       "      <td>new york city metropolitan area</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>unknown</td>\n",
       "      <td>excel, statistics, data analysis</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>cybercoders</td>\n",
       "      <td>yakima, wa</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>remote</td>\n",
       "      <td>sql, power bi, statistics, data analysis, data...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>techhuman</td>\n",
       "      <td>united states</td>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>remote</td>\n",
       "      <td>sql, tableau, data analysis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data analysis</td>\n",
       "      <td>hamilton porter</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>onsite</td>\n",
       "      <td>python, tableau</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title          company                         location  \\\n",
       "0   data analysis             meta                     new york, ny   \n",
       "1   data analysis             meta                san francisco, ca   \n",
       "2   data analysis             meta                  los angeles, ca   \n",
       "3   data analysis             meta                   washington, dc   \n",
       "4   data analysis        pinterest                      chicago, il   \n",
       "5   data analysis          fanduel                     new york, ny   \n",
       "6   data analysis          netflix                  los angeles, ca   \n",
       "7   data analysis          fanduel                     new york, ny   \n",
       "8   data analysis      sbh fashion                     new york, ny   \n",
       "9   data analysis        pinterest                     new york, ny   \n",
       "10  data analysis        pinterest                san francisco, ca   \n",
       "11  data analysis             meta                     new york, ny   \n",
       "12  data analysis          fanduel                      atlanta, ga   \n",
       "13  data analysis        finthrive                    united states   \n",
       "14  data analysis   alice + olivia                     new york, ny   \n",
       "15  data analysis           google                     new york, ny   \n",
       "16  data analysis          bvlgari  new york city metropolitan area   \n",
       "17  data analysis      cybercoders                       yakima, wa   \n",
       "18  data analysis        techhuman                    united states   \n",
       "19  data analysis  hamilton porter                     new york, ny   \n",
       "\n",
       "   date_posted work_type                                             skills  \\\n",
       "0   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "1   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "2   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "3   2025-04-14   unknown  python, sql, tableau, r, machine learning, sta...   \n",
       "4   2025-04-16   unknown                            python, sql, statistics   \n",
       "5   2025-04-11    hybrid    python, sql, excel, tableau, data visualization   \n",
       "6   2025-04-10   unknown                         python, sql, data analysis   \n",
       "7   2025-04-13   unknown  python, sql, excel, tableau, r, data visualiza...   \n",
       "8   2025-04-12    remote  python, sql, excel, tableau, data analysis, da...   \n",
       "9   2025-04-16   unknown                            python, sql, statistics   \n",
       "10  2025-04-16   unknown                            python, sql, statistics   \n",
       "11  2025-04-14   unknown               sql, machine learning, data analysis   \n",
       "12  2025-04-11    hybrid    python, sql, excel, tableau, data visualization   \n",
       "13  2025-04-15   unknown  sql, excel, power bi, tableau, data analysis, etl   \n",
       "14  2025-04-15   unknown              sql, excel, statistics, data analysis   \n",
       "15  2025-04-14   unknown  python, sql, machine learning, statistics, etl...   \n",
       "16  2025-04-11   unknown                   excel, statistics, data analysis   \n",
       "17  2025-04-15    remote  sql, power bi, statistics, data analysis, data...   \n",
       "18  2025-04-11    remote                        sql, tableau, data analysis   \n",
       "19  2025-04-16    onsite                                    python, tableau   \n",
       "\n",
       "    experience  \n",
       "0          2.0  \n",
       "1          2.0  \n",
       "2          2.0  \n",
       "3          2.0  \n",
       "4          4.0  \n",
       "5          3.0  \n",
       "6          0.0  \n",
       "7          2.0  \n",
       "8          3.0  \n",
       "9          4.0  \n",
       "10         4.0  \n",
       "11         5.0  \n",
       "12         3.0  \n",
       "13         1.0  \n",
       "14         5.0  \n",
       "15         3.0  \n",
       "16         3.0  \n",
       "17         0.0  \n",
       "18         0.0  \n",
       "19         5.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data analysis', 'data science', 'data engineering',\n",
       "       'machine learning & AI', 'junior frontend developer'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check after replacement \n",
    "df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this unique row that doesn't related wiht the data jobs \n",
    "df = df[df['title']!='junior frontend developer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Drop rows where skills is None or empty\n",
    "skills_series = df['skills'].dropna()\n",
    "skills_list = []\n",
    "\n",
    "for skills in skills_series:\n",
    "    skills_split = [skill.strip() for skill in skills.split(',') if skill.strip().lower() != 'none']\n",
    "    skills_list.extend(skills_split)\n",
    "\n",
    "# Count the frequency of each skill\n",
    "skill_counts = Counter(skills_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sql': 240,\n",
       "         'python': 229,\n",
       "         'machine learning': 115,\n",
       "         'statistics': 99,\n",
       "         'etl': 88,\n",
       "         'tableau': 83,\n",
       "         'r': 82,\n",
       "         'data analysis': 78,\n",
       "         'spark': 72,\n",
       "         'power bi': 57,\n",
       "         'data visualization': 55,\n",
       "         'big data': 55,\n",
       "         'excel': 52,\n",
       "         'hadoop': 26,\n",
       "         'tensorflow': 23,\n",
       "         'deep learning': 22,\n",
       "         'scikit-learn': 18,\n",
       "         'pandas': 15,\n",
       "         'numpy': 12,\n",
       "         'keras': 9,\n",
       "         'data wrangling': 7,\n",
       "         'matplotlib': 4,\n",
       "         'plotly': 1,\n",
       "         'seaborn': 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_job.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
